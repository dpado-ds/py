{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сбор и анализ отзывов о ресторанах на tripadvisor.ru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В проекте, вооружившись статьями из разных уважаемых источников (например, [\"Ведомости\"](https://www.vedomosti.ru/lifestyle/articles/2016/03/25/637995-vesna-v-restoranah-moskvi),) я решила посмотреть, можно ли, обработав данные о московских ресторанах с известными средним чеком и датой первого отзыва на сайте tripadvisor.com, сделать вывод о том, что в кризис посетители стали предпочитать более бюджетные рестораны"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "import urllib\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import xlsxwriter\n",
    "writer = pd.ExcelWriter('reviews.xlsx', engine='xlsxwriter')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Загрузить стартовую страницу и подготовить файл для записи\n",
    "driver = webdriver.Chrome('C:/Users/Daria/Documents/chromedriver.exe')\n",
    "ref = 'https://www.tripadvisor.com/Restaurants-g298484-Moscow_Central_Russia.html#MAINWRAP'\n",
    "driver.get(ref)\n",
    "filters = ['//*[@id=\"jfy_filter_bar_price\"]/div[2]/div[1]',\n",
    "           '//*[@id=\"jfy_filter_bar_price\"]/div[2]/div[2]',\n",
    "           '//*[@id=\"jfy_filter_bar_price\"]/div[2]/div[3]']\n",
    "for f in filters:\n",
    "    i = 0\n",
    "    while not 'selected' in driver.find_element_by_xpath(f).get_attribute('class') or i > 10:\n",
    "        driver.find_element_by_xpath(f).click()\n",
    "        time.sleep(1)\n",
    "        i += 1\n",
    "source = driver.page_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Функция выгружает рестораны с ненулевым количеством отзывов, получает имя ресторана, средний чек и ссылку на страницу с отзывами\n",
    "def download_rests_data(page, file):\n",
    "    soup = bs(page, 'lxml')\n",
    "    divs = soup.findAll('div', class_='shortSellDetails')\n",
    "    # Удалить рестораны с пустыми отзывами - exception из-за разной двух вариантов структуры тэгов с нулевыми отзывами\n",
    "    rests_with_reviews = []\n",
    "    for div in divs:\n",
    "        try:\n",
    "            if div.find('div', class_ = \"rating\").a.text.strip() != 'Оставить первый отзыв об этом ресторане':\n",
    "                rests_with_reviews.append(div)\n",
    "        except:\n",
    "            pass\n",
    "    # Получить имя ресторана\n",
    "    names = [div.find('h3', class_='title').text.strip() for div in rests_with_reviews]\n",
    "    print(len(names))\n",
    "    # Получить средний чек\n",
    "    checks = []\n",
    "    for div in rests_with_reviews:\n",
    "        try:\n",
    "            check = div.find('span', class_='price').text.strip()\n",
    "        except:\n",
    "            check = 'NaN'\n",
    "        checks.append(check)\n",
    "    # Получить ссылки на отзывы\n",
    "    hrefs_raw = [div.find('span', class_='reviewCount') for div in rests_with_reviews]\n",
    "    hrefs = ['https://www.tripadvisor.ru' + i.a['href'] for i in hrefs_raw]\n",
    "    # дописать в файл\n",
    "    database = pd.DataFrame(data = list(zip(names, checks, hrefs)))\n",
    "    with open(file, 'a') as f:\n",
    "        database.to_csv(f, encoding='unicode', header = False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Проходим по выданным фильтром страницам и собираем начальную информацию\n",
    "page_num = 1\n",
    "position = 30\n",
    "last_page = int(driver.find_element_by_css_selector(\"#EATERY_LIST_CONTENTS > div.deckTools.btm > div > div > a:nth-child(8)\").text)\n",
    "print(last_page)\n",
    "while page_num <= 5:\n",
    "    href = 'https://www.tripadvisor.ru/RestaurantSearch-g298484-oa' + str(position) + '-p15-Moscow_Central_Russia.html#EATERY_LIST_CONTENTS'\n",
    "    driver.get(href)\n",
    "    source = driver.page_source\n",
    "    download_rests_data(source, 'tripadvisor_restaurants.csv')\n",
    "    print(page_num, \"DONE\")\n",
    "    page_num = page_num + 1\n",
    "    position = position + 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Открываем получившийся CSV в виде датафрейма, добавляем хэдеры\n",
    "database = pd.read_csv('tripadvisor_restaurants.csv', header = None, names = ['Name', 'Avg check', 'Hrefs'], encoding = 'cp1251')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "database[1:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут средний чек отобразился неправильно из-за встроенной кодировки, но в самом csv-файле все в порядке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_revs_data(page):\n",
    "    driver.get(page)\n",
    "    try:\n",
    "        last_page = int(driver.find_element_by_xpath((\"//a[@class='pageNum taLnk' and contains(@onclick,'last')]\")).text)\n",
    "    except:\n",
    "        last_page = 1\n",
    "    months = {' января ':'01', ' февраля ':'02', ' марта ':'03', ' апреля ':'04', ' мая ':'05', ' июня ':'06', ' июля ':'07', ' августа ':'08',\n",
    "            ' сентября ':'09', ' октября ':'10', ' ноября ':'11', ' декабря ':'12'}\n",
    "    pattern = re.compile(r'\\b(' +'|'.join(months.keys())+ r')\\b')\n",
    "    page_num = 1\n",
    "    position = 10\n",
    "    dates = []\n",
    "    ratings = []\n",
    "    while page_num <= last_page:\n",
    "        if page_num == 1:\n",
    "            rev_href = page\n",
    "        else:\n",
    "            rev_href = re.sub(r'^((.*?-.*?){2})-', r'\\1-or%s-' %position, page)\n",
    "            if page_num < last_page:\n",
    "                position += 10\n",
    "            driver.get(rev_href)\n",
    "        rest_soup = bs(driver.page_source,'lxml')\n",
    "        review_bubbles = rest_soup.findAll('div', class_='reviewItemInline')\n",
    "        for bubble in review_bubbles:\n",
    "            # Получим даты отзывов\n",
    "            raw_date1 = bubble.find('span', class_='ratingDate')\n",
    "            # Из-за неоднородной структуры страниц несколько исключений\n",
    "            try:\n",
    "                raw_date1.string.replace_with(raw_date1.string.strip())\n",
    "            except:\n",
    "                raw_date1.previousSibling.replace_with(raw_date1.previousSibling.strip())\n",
    "            try:\n",
    "                date = raw_date1['title']\n",
    "            except:\n",
    "                date = raw_date1.text.split(' ', 2)[-1]\n",
    "            raw_date2 = pattern.sub(lambda x: months[x.group()], date)\n",
    "                # В некоторых случаях strptime не парсит даты, например '3122013' возвращает ошибку out of range\n",
    "            if len(raw_date2) == 7:\n",
    "                raw_date2 = '0' + raw_date2\n",
    "            date_fine = datetime.datetime.strptime(raw_date2, \"%d%m%Y\").date()\n",
    "            dates.append(date_fine)\n",
    "                # Собираем рейтинги\n",
    "            rating = int(bubble.img['alt'].split(' ',1)[0])\n",
    "            ratings.append(rating)\n",
    "        print(page_num, ' done')\n",
    "        page_num += 1\n",
    "    stat = pd.DataFrame({'Оценка':ratings, 'Дата':dates})\n",
    "    return stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stats = []\n",
    "name = database['Name'][database['Hrefs'] == 'https://www.tripadvisor.ru/Restaurant_Review-g298484-d6495969-Reviews-Kitayskaya_Gramota-Moscow_Central_Russia.html#REVIEWS']\n",
    "name.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Для каждого ресторана заходим в href, проходимся по ссылкам и собираем дату и рейтинг для каждого отзыва\n",
    "# Записываем даты и рейтинги в structured numpy array\n",
    "# Добавляем в датафрейм column и помещаем туда массив для каждого ресторана\n",
    "for href in database['Hrefs']:\n",
    "    name = database['Name'][database['Hrefs'] == href]\n",
    "    print(name)\n",
    "    revs = get_revs_data(href)\n",
    "    revs.to_excel(writer, sheet_name = str(name.values[0]))\n",
    "    print(name, 'DONE')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Старый код и графики"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "График даты первого отзыва на размер (текущего) чека:\n",
    "------------------------------------------------\n",
    "Можно визуально оценить зависимость даты первого отзыва от размера среднего чека ресторана. Идея в том, что дата первого отзыва приближает момент, когда ресторан был открыт / замечен посетителями. Соображения о сумме чека, указанные в начале, остаются в силе"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "database['1st revw date'] = pd.Series([database['Stats'][i][0].datetime64 for i in range(0, len(database.index))])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "database[1:10]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "database.plot(x = '1st revw date',  y = 'Avg check', figsize = [40, 20])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Видно, что после 2015 г. был только один большой пик - первый отзыв на ресторан с размером чека более 15000 руб, также уменьшилось количество первых отзывов на рестораны с чеком в рамках 7000-15000.  Также можно заметить, что количество первых отзывов на рестораны с чеком <5000 руб увеличилось по сравнению с последними двумя годами (по более плотному заполнению пиками), но это может быть объяснено многими факторами, помимо возросшего внимания потребителей к недорогим ресторанам: например, возросшей популярностью самого ресурса tripadvisor.ru"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "В следующем графике была сделана попытка визуализировать частотное распределение всех отзывов в зависимости от среднего чека"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "lst = []\n",
    "for i in range(0, len(database.index)):\n",
    "    for j in range(0, database['Stats'][i].size):\n",
    "        x = (database['Stats'][i][j].datetime64, database['Avg check'][i])\n",
    "        lst.append(x)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "date_check_arr = np.rec.array(lst, dtype=[('datetime64', 'O'), ('check', 'f')])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "plt.figure(figsize=(80,60))\n",
    "plt.scatter(date_check_arr.datetime64, date_check_arr.check)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Но как видно, такая картинка ничего не дала, потому что точки расположены слишком плотно :(   \n",
    "Поэтому для третьего графика было решено рассчитать процентное изменение количества отзывов за каждый месяц, разделить линии ресторанов по цвету в зависимости от величины чека и посмотреть, линии какого цвета будут стремиться преимущественно к верхнему, а какие - к нижнему сегменту графика в период с 2015 г."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "def get_percent_chnge(arr, lst):\n",
    "    months = np.arange('2008-01', '2016-05', dtype='datetime64').astype('O')\n",
    "    months_counts = np.core.records.fromarrays([months, np.zeros_like(months, dtype = 'i')], names = 'date, count')\n",
    "    for i in arr:\n",
    "        for j in months_counts:\n",
    "            if i.datetime64.month==j.date.month and i.datetime64.year==j.date.year:\n",
    "                j.count += 1\n",
    "    base_value_index = np.nonzero(months_counts.count)[0][0]-1\n",
    "    months_counts.count = np.cumsum(months_counts.count)\n",
    "    change_array = np.diff(months_counts.count) / np.abs(months_counts[:-1].count)*100\n",
    "    change_array[base_value_index] = 0\n",
    "    change_array[np.isnan(change_array)] = 0\n",
    "    change_array = np.insert(change_array, 1, 0)\n",
    "    months_change = np.core.records.fromarrays([months, np.cumsum(change_array)], dtype=[('date', 'O'), ('change', '<f2')], names = 'date, change')\n",
    "    lst.append(months_change)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "percent_changes = []\n",
    "for i in database['Stats']:\n",
    "    get_percent_chnge(i, percent_changes)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "database['% chnge 2008-2016'] = percent_changes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "filters = np.linspace(database['Avg check'].min(), database['Avg check'].max()+1, 30)\n",
    "filter_pairs = [tuple(p) for p in np.split(filters, 15)]\n",
    "color_ids = np.linspace(0, 1, len(filter_pairs))\n",
    "plt.figure(figsize=(100,80))\n",
    "for f,i in enumerate(color_ids):\n",
    "    x = database['% chnge 2008-2016'][(database['Avg check']>filter_pairs[f][0]) & (database['Avg check']<filter_pairs[f][1])]\n",
    "    for j in x:\n",
    "        plt.plot(j.date, j.change, color=plt.cm.cool(i), lw=9)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "На этом графике рестораны от более дорогого чека к более дешевому меняют цвет с фиолетового на голубой. Хотя график опять очень плотный, видно, что динамика изменения количества отзывов выше для ресторанов из более бюджетных категорий, причем этот тренд наметился даже раньше 2015 г, что, возможно, объясняется спецификой ресурса tripadvisor. Есть несколько подозрительно резко набравших отзывы бюджетных ресторанов, для которых будет интересно посмотреть на рейтинг отзывов. Видно, что для большинства ресторанов наклон кривой прироста количества отзывов падает, что, в том числе, говорит о том, что люди уменьшили число походов в рестораны в принципе. Такая приближенная картинка согласуется с предположениями, выдвинутыми в начале."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "В заключение нужно пояснить, что рейтинги, собранные вместе с датой каждого отзыва, не использованные в данном проекте, я собрала, чтобы воспользоваться ими в следующем проекте на R.\n",
    "Спасибо за внимание :)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
